{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing Credit Recognizer Feasability\n",
    "\n",
    "Within this notebook I explore the feasability of the idea to see if using convolutional we can classify frames into classes of Movie Screenshot and Closing Credit.\n",
    "\n",
    "At this stage you should have the dataset in place in separate directories, we first create directories for training and validation data and break the dataset into training and validation before training the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==0.15.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 1)) (0.15.0)\n",
      "Requirement already satisfied: argon2-cffi==21.3.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 2)) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 3)) (21.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: async-generator==1.10 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 5)) (1.10)\n",
      "Requirement already satisfied: attrs==22.1.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 6)) (22.1.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: bleach==4.1.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 8)) (4.1.0)\n",
      "Requirement already satisfied: cached-property==1.5.2 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 9)) (1.5.2)\n",
      "Requirement already satisfied: cachetools==4.2.4 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 10)) (4.2.4)\n",
      "Requirement already satisfied: certifi==2022.9.24 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 11)) (2022.9.24)\n",
      "Requirement already satisfied: cffi==1.15.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 12)) (1.15.1)\n",
      "Requirement already satisfied: charset-normalizer==2.0.12 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 13)) (2.0.12)\n",
      "Requirement already satisfied: clang==5.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 14)) (5.0)\n",
      "Requirement already satisfied: colorama==0.4.5 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 15)) (0.4.5)\n",
      "Requirement already satisfied: cycler==0.11.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 16)) (0.11.0)\n",
      "Requirement already satisfied: dataclasses==0.8 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 17)) (0.8)\n",
      "Requirement already satisfied: decorator==5.1.1 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 18)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 19)) (0.7.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 20)) (0.4)\n",
      "Requirement already satisfied: fastprogress==1.0.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 21)) (1.0.3)\n",
      "Requirement already satisfied: flatbuffers==1.12 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 22)) (1.12)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 23)) (0.4.0)\n",
      "Requirement already satisfied: google-auth==1.35.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 24)) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.6 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 25)) (0.4.6)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 26)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.48.2 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 27)) (1.48.2)\n",
      "Requirement already satisfied: h5py==3.1.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 28)) (3.1.0)\n",
      "Requirement already satisfied: idna==3.4 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 29)) (3.4)\n",
      "Requirement already satisfied: importlib-metadata==4.8.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 30)) (4.8.3)\n",
      "Requirement already satisfied: ipykernel==5.5.6 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 31)) (5.5.6)\n",
      "Requirement already satisfied: ipython==7.16.3 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 32)) (7.16.3)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 33)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==7.7.2 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 34)) (7.7.2)\n",
      "Requirement already satisfied: jedi==0.17.2 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 35)) (0.17.2)\n",
      "Requirement already satisfied: Jinja2==3.0.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 36)) (3.0.3)\n",
      "Requirement already satisfied: jsonschema==3.2.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 37)) (3.2.0)\n",
      "Requirement already satisfied: jupyter==1.0.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 38)) (1.0.0)\n",
      "Requirement already satisfied: jupyter-client==7.1.2 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 39)) (7.1.2)\n",
      "Requirement already satisfied: jupyter-console==6.4.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 40)) (6.4.3)\n",
      "Requirement already satisfied: jupyter-core==4.9.2 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 41)) (4.9.2)\n",
      "Requirement already satisfied: jupyterlab-pygments==0.1.2 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 42)) (0.1.2)\n",
      "Requirement already satisfied: jupyterlab-widgets==1.1.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 43)) (1.1.1)\n",
      "Requirement already satisfied: keras==2.6.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 44)) (2.6.0)\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.2 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 45)) (1.1.2)\n",
      "Requirement already satisfied: kiwisolver==1.3.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 46)) (1.3.1)\n",
      "Requirement already satisfied: Markdown==3.3.7 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 47)) (3.3.7)\n",
      "Requirement already satisfied: MarkupSafe==2.0.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 48)) (2.0.1)\n",
      "Requirement already satisfied: matplotlib==3.3.4 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 49)) (3.3.4)\n",
      "Requirement already satisfied: mistune==0.8.4 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 50)) (0.8.4)\n",
      "Requirement already satisfied: nbclient==0.5.9 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 51)) (0.5.9)\n",
      "Requirement already satisfied: nbconvert==6.0.7 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 52)) (6.0.7)\n",
      "Requirement already satisfied: nbformat==5.1.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 53)) (5.1.3)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 54)) (1.5.6)\n",
      "Requirement already satisfied: notebook==6.4.10 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 55)) (6.4.10)\n",
      "Requirement already satisfied: numpy==1.19.5 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 56)) (1.19.5)\n",
      "Requirement already satisfied: oauthlib==3.2.2 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 57)) (3.2.2)\n",
      "Requirement already satisfied: opencv-contrib-python==4.6.0.66 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 58)) (4.6.0.66)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 59)) (3.3.0)\n",
      "Requirement already satisfied: packaging==21.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 60)) (21.3)\n",
      "Requirement already satisfied: pandocfilters==1.5.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 61)) (1.5.0)\n",
      "Requirement already satisfied: parso==0.7.1 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 62)) (0.7.1)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 63)) (0.7.5)\n",
      "Requirement already satisfied: Pillow==8.4.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 64)) (8.4.0)\n",
      "Requirement already satisfied: prometheus-client==0.15.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 65)) (0.15.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.32 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 66)) (3.0.32)\n",
      "Requirement already satisfied: protobuf==3.19.6 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 67)) (3.19.6)\n",
      "Requirement already satisfied: pyasn1==0.4.8 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 68)) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 69)) (0.2.8)\n",
      "Requirement already satisfied: pycparser==2.21 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 70)) (2.21)\n",
      "Requirement already satisfied: Pygments==2.13.0 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 71)) (2.13.0)\n",
      "Requirement already satisfied: pyparsing==3.0.7 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 72)) (3.0.7)\n",
      "Requirement already satisfied: pyrsistent==0.18.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 73)) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 74)) (2.8.2)\n",
      "Requirement already satisfied: pywin32==305 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 75)) (305)\n",
      "Requirement already satisfied: pywinpty==1.1.6 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 76)) (1.1.6)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 77)) (24.0.1)\n",
      "Requirement already satisfied: qtconsole==5.2.2 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 78)) (5.2.2)\n",
      "Requirement already satisfied: QtPy==2.0.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 79)) (2.0.1)\n",
      "Requirement already satisfied: requests==2.27.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 80)) (2.27.1)\n",
      "Requirement already satisfied: requests-oauthlib==1.3.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 81)) (1.3.1)\n",
      "Requirement already satisfied: rsa==4.9 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 82)) (4.9)\n",
      "Requirement already satisfied: scipy==1.5.4 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 83)) (1.5.4)\n",
      "Requirement already satisfied: Send2Trash==1.8.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 84)) (1.8.0)\n",
      "Requirement already satisfied: six==1.15.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 85)) (1.15.0)\n",
      "Requirement already satisfied: tensorboard==2.6.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 86)) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.6.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 87)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 88)) (1.8.1)\n",
      "Requirement already satisfied: tensorflow==2.6.2 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 89)) (2.6.2)\n",
      "Requirement already satisfied: tensorflow-estimator==2.6.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 90)) (2.6.0)\n",
      "Requirement already satisfied: termcolor==1.1.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 91)) (1.1.0)\n",
      "Requirement already satisfied: terminado==0.12.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 92)) (0.12.1)\n",
      "Requirement already satisfied: testpath==0.6.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 93)) (0.6.0)\n",
      "Requirement already satisfied: tornado==6.1 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 94)) (6.1)\n",
      "Requirement already satisfied: traitlets==4.3.3 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 95)) (4.3.3)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 96)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3==1.26.12 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 97)) (1.26.12)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from -r requirements.txt (line 98)) (0.2.5)\n",
      "Requirement already satisfied: webencodings==0.5.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 99)) (0.5.1)\n",
      "Requirement already satisfied: Werkzeug==2.0.3 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 100)) (2.0.3)\n",
      "Requirement already satisfied: widgetsnbextension==3.6.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 101)) (3.6.1)\n",
      "Requirement already satisfied: wrapt==1.12.1 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 102)) (1.12.1)\n",
      "Requirement already satisfied: zipp==3.6.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from -r requirements.txt (line 103)) (3.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\issae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from astunparse==1.6.3->-r requirements.txt (line 4)) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\issae\\appdata\\roaming\\python\\python36\\site-packages (from google-auth==1.35.0->-r requirements.txt (line 24)) (59.6.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./Lib/site-packages')\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers, models, optimizers\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "import scipy\n",
    "\n",
    "data_path = Path('../data/')\n",
    "directories = ['closing_credits', 'movie_screenshot']\n",
    "\n",
    "data_path = Path('../data/')\n",
    "dataset_path = data_path/'dataset'\n",
    "train = dataset_path/'train'\n",
    "valid = dataset_path/'valid'\n",
    "\n",
    "for directory in directories:\n",
    "    train_path = train/directory\n",
    "    train_path.mkdir(parents=True, exist_ok=True)\n",
    "    valid_path = valid/directory\n",
    "    valid_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this block of code only once to randomly break the images into training and validation and move them to the corresponding directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for directory in directories:\n",
    "#     fnames = sorted(os.listdir(dataset_path/directory))\n",
    "#     fnames = [fname for fname in fnames if fname[-4] == '.' or fname[-5] == '.']\n",
    "#     indices = np.arange(len(fnames), dtype=np.int16)\n",
    "#     np.random.shuffle(fnames)\n",
    "#     train_path = train/directory\n",
    "#     valid_path = valid/directory\n",
    "#     break_point = int(len(fnames) * 0.2)\n",
    "#     for fname in fnames[:break_point]:\n",
    "#         shutil.copyfile(dataset_path/directory/fname, valid_path/fname)\n",
    "#     for fname in fnames[break_point:]:\n",
    "#         shutil.copyfile(dataset_path/directory/fname, train_path/fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the idea using an arbitrary CNN\n",
    "\n",
    "For the first attempt I created a simple arbitrary Convolutional Neural Network to see if it can differentiate between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the data generators\n",
    "\n",
    "In order to feed the data to our network we have to create Keras Data Generators. No data augmentation at this point is done. We only normalise the values to be between 0 and 1. There are 400 training examples and 100 for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 401 images belonging to 2 classes.\n",
      "Found 99 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=40,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        valid,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=25,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the first model\n",
    "\n",
    "Finally, model is being trained in the following code block and we save it on the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\issae\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.6496 - acc: 0.6759 - val_loss: 0.6397 - val_acc: 0.7172\n",
      "Epoch 2/35\n",
      "10/10 [==============================] - 10s 968ms/step - loss: 0.5437 - acc: 0.7119 - val_loss: 0.6159 - val_acc: 0.5758\n",
      "Epoch 3/35\n",
      "10/10 [==============================] - 10s 985ms/step - loss: 0.5632 - acc: 0.6842 - val_loss: 0.6215 - val_acc: 0.7576\n",
      "Epoch 4/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.5819 - acc: 0.7285 - val_loss: 0.6272 - val_acc: 0.7677\n",
      "Epoch 5/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.4426 - acc: 0.7729 - val_loss: 0.6002 - val_acc: 0.7879\n",
      "Epoch 6/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4988 - acc: 0.7562 - val_loss: 0.5596 - val_acc: 0.8485\n",
      "Epoch 7/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4685 - acc: 0.7618 - val_loss: 0.5372 - val_acc: 0.7475\n",
      "Epoch 8/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4650 - acc: 0.8089 - val_loss: 0.5315 - val_acc: 0.8485\n",
      "Epoch 9/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3953 - acc: 0.8421 - val_loss: 0.5095 - val_acc: 0.8586\n",
      "Epoch 10/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.4198 - acc: 0.8283 - val_loss: 0.5166 - val_acc: 0.8485\n",
      "Epoch 11/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3977 - acc: 0.8421 - val_loss: 0.4766 - val_acc: 0.8384\n",
      "Epoch 12/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3776 - acc: 0.8449 - val_loss: 0.4564 - val_acc: 0.8485\n",
      "Epoch 13/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3519 - acc: 0.8560 - val_loss: 0.4469 - val_acc: 0.8586\n",
      "Epoch 14/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3830 - acc: 0.8366 - val_loss: 0.4305 - val_acc: 0.8586\n",
      "Epoch 15/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3136 - acc: 0.8920 - val_loss: 0.4158 - val_acc: 0.8687\n",
      "Epoch 16/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3809 - acc: 0.8560 - val_loss: 0.4417 - val_acc: 0.8485\n",
      "Epoch 17/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.3098 - acc: 0.8670 - val_loss: 0.4219 - val_acc: 0.8586\n",
      "Epoch 18/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2715 - acc: 0.9030 - val_loss: 0.4141 - val_acc: 0.8485\n",
      "Epoch 19/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3460 - acc: 0.8643 - val_loss: 0.3949 - val_acc: 0.8485\n",
      "Epoch 20/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2433 - acc: 0.9197 - val_loss: 0.3970 - val_acc: 0.8788\n",
      "Epoch 21/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2608 - acc: 0.9114 - val_loss: 0.3647 - val_acc: 0.8586\n",
      "Epoch 22/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2833 - acc: 0.9114 - val_loss: 0.3633 - val_acc: 0.8687\n",
      "Epoch 23/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2345 - acc: 0.9114 - val_loss: 0.3586 - val_acc: 0.8687\n",
      "Epoch 24/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2670 - acc: 0.9030 - val_loss: 0.3662 - val_acc: 0.8788\n",
      "Epoch 25/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2245 - acc: 0.9141 - val_loss: 0.3366 - val_acc: 0.8687\n",
      "Epoch 26/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2162 - acc: 0.9280 - val_loss: 0.3389 - val_acc: 0.8788\n",
      "Epoch 27/35\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.2761 - acc: 0.9141 - val_loss: 0.3491 - val_acc: 0.8586\n",
      "Epoch 28/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2147 - acc: 0.9114 - val_loss: 0.3594 - val_acc: 0.8586\n",
      "Epoch 29/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1913 - acc: 0.9391 - val_loss: 0.3430 - val_acc: 0.8586\n",
      "Epoch 30/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2816 - acc: 0.8920 - val_loss: 0.3530 - val_acc: 0.8384\n",
      "Epoch 31/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1850 - acc: 0.9307 - val_loss: 0.3339 - val_acc: 0.8586\n",
      "Epoch 32/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1507 - acc: 0.9446 - val_loss: 0.3428 - val_acc: 0.8586\n",
      "Epoch 33/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2470 - acc: 0.9114 - val_loss: 0.3304 - val_acc: 0.8788\n",
      "Epoch 34/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.1649 - acc: 0.9252 - val_loss: 0.3353 - val_acc: 0.8586\n",
      "Epoch 35/35\n",
      "10/10 [==============================] - 11s 1s/step - loss: 0.2391 - acc: 0.9252 - val_loss: 0.3512 - val_acc: 0.8283\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=10,\n",
    "      epochs=35,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=4)\n",
    "\n",
    "model.save('closing_credits_simple_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting training and validation's accuracy and loss\n",
    "\n",
    "It can be observed that model is doing very well already! Achieving an accuracy above 0.90 and no sign of overfitting. Given this result it can be said that we can use such a model for our purposes, and so it is feasable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_train_vs_valid(history):\n",
    "    acc = history.history['acc']\n",
    "    loss = history.history['loss']\n",
    "    val_acc = history.history['val_acc']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc)+1)\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(8)\n",
    "    fig.set_figwidth(16)\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    ax.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "    ax.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "    ax.set_title('Training Accuracy vs Validation Accuracy')\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel('accuracy')\n",
    "    ax.legend()\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    ax.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    ax.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "    ax.set_title('Training Loss vs Validation Loss')\n",
    "    ax.set_xlabel('epochs')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_train_vs_valid(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning Using ResNet50\n",
    "\n",
    "Now that we have reached the conclusion that it's possible to differentiate between rolling credits and snapshots of movies let's try out a pretrained ResNet50 model to check what would happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = ResNet50(weights='imagenet',\n",
    "                     include_top=False,\n",
    "                     input_shape=(224, 224, 3))\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing the layers except the last ones\n",
    "\n",
    "Here I have freezed all the layers except the last 35 layers to disable weights getting updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False\n",
    "for layer in conv_base.layers[-35:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\issae\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "c:\\Users\\issae\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 2.2022 - acc: 0.6981 - val_loss: 0.6410 - val_acc: 0.5758\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.1740 - acc: 0.9252 - val_loss: 0.6255 - val_acc: 0.5960\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.3846 - acc: 0.8698 - val_loss: 0.6954 - val_acc: 0.5253\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.2462 - acc: 0.9224 - val_loss: 0.6497 - val_acc: 0.5657\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.1388 - acc: 0.9418 - val_loss: 0.5726 - val_acc: 0.6667\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.0360 - acc: 0.9875 - val_loss: 0.5417 - val_acc: 0.8182\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.1143 - acc: 0.9529 - val_loss: 0.5164 - val_acc: 0.7576\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.0354 - acc: 0.9834 - val_loss: 0.4748 - val_acc: 0.8485\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.1633 - acc: 0.9474 - val_loss: 0.4374 - val_acc: 0.9394\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.0201 - acc: 0.9917 - val_loss: 0.4424 - val_acc: 0.7778\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.RMSprop(learning_rate=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=10,\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "And huge success! It took one epoch to achieve 0.99 accuracy! Therefore, here we save this model to be used for the actual service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-619ab0b80b9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models/closing_credits_Resnet50.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplot_train_vs_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('models/closing_credits_Resnet50.h5')\n",
    "\n",
    "plot_train_vs_valid(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0238941942c372a93add45ab3296658c37e5e41742d749137840208421d6893e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
