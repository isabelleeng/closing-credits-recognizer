{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the videos\n",
    "\n",
    "This notebook contains info on reading the video files preprocessing them and feed the frames to the trained network and returning the timestamp (in milliseconds) when credits start running and its frame ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('./Lib/site-packages')\n",
    "# !{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the ResNet50 model created in the previous notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/share/virtualenvs/closing-credits-recognizer-L-5h7F88/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/share/virtualenvs/closing-credits-recognizer-L-5h7F88/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model('model/closing_credits_Resnet50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openning the video file and initializing the required variables\n",
    "Since the model has been trained on square images we want to only extract the center square from the frame. Therefore, _cutoff_ variable is defined to skip columns from left and right of the frame later on. To test this pipeline, an open source movie called _Sintel_ is used which is available for downloading at https://durian.blender.org/download/ (Specifically, 2048 x 872 (270 Mb, mp4, 5.1) version was used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [] # Contains the timestamp (in milliseconds) and frame ID of all frames fed into the model\n",
    "frames = [] # Contains the frames themselves\n",
    "\n",
    "video_file = '../data/sintel-2048-surround.mp4'\n",
    "capture = cv2.VideoCapture(video_file)\n",
    "\n",
    "width = capture.get(3)\n",
    "height = capture.get(4)\n",
    "cutoff = int((width - height)/2)\n",
    "frame_rate = capture.get(5)\n",
    "total_frames = capture.get(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and formatting the frames\n",
    "\n",
    "Here we read the frames one by one and only store the frames from the last 25% of the video because credits wouldn't normally start any earlier of that point in series and movies. In addition we capture a square at the center of the frame and resize is to be fed into ResNet50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(capture.isOpened()):\n",
    "    frame_info = {\"time_progress\": capture.get(0),\n",
    "                  \"frame_id\": capture.get(1)}\n",
    "    ret, frame = capture.read()\n",
    "    if ret != True:\n",
    "        break\n",
    "    if frame_info['frame_id']/total_frames > 0.75 and frame_info['frame_id'] % math.floor(frame_rate/10) == 0:\n",
    "        metadata.append(frame_info)\n",
    "        frame = frame[:, cutoff:-cutoff, :]\n",
    "        frame = cv2.resize(frame, (224, 224))/255.0\n",
    "        frames.append(frame)\n",
    "\n",
    "frames = np.array(frames)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = model.predict_classes(frames)\n",
    "estimates = np.array([x[0] for x in prediction_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the frame ID where the credits start rolling\n",
    "\n",
    "The following function gets the predictions and runs a sliding window to check where we would have 50 (window_size) consecutive frames classified as credits and returns the beginning index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_index(estimates, window_size=50):\n",
    "    window = np.zeros((window_size,))\n",
    "    count = 0\n",
    "    for i in range(estimates.shape[0]-window_size):\n",
    "        if count == 10:\n",
    "            return index\n",
    "        if np.sum(estimates[i:(i+window_size)] == window)/window_size > 0.95:\n",
    "            if count == 0:\n",
    "                index = i\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0\n",
    "            index = None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the metadata\n",
    "\n",
    "Finally, given the index we can return the timestamp in the movie where credits start rolling and its frame number which in this case it starts at 743916 milliseconds into the movie at frame 17854. Which is accurate! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_progress': 743916.6666666666, 'frame_id': 17854.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[get_starting_index(estimates)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0238941942c372a93add45ab3296658c37e5e41742d749137840208421d6893e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
